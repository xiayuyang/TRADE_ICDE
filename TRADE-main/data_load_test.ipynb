{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_txt(file_path, cams_ratio): \n",
    "    # 抽帧，有选择的加载gt文件中的行\n",
    "    data_dict = {} \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # 从每一行提取tid、fid和bbox\n",
    "            fid,tid,x1,y1,w,h,_,_,_,_ = map(int, line.strip().split(','))\n",
    "            data = [tid, x1, y1, w, h]\n",
    "\n",
    "            if fid % cams_ratio != 0:\n",
    "                continue\n",
    "            if fid not in data_dict:\n",
    "                data_dict[fid] = {'gt':[]} \n",
    "            data_dict[fid]['gt'].append(data)\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "gt_path = 'datasets/AIC22_Track1_MTMC_Tracking/train/S10/c001/gt/gt.txt'\n",
    "ratio = 2\n",
    "gt_dict = read_data_from_txt(gt_path, ratio)\n",
    "print(len(gt_dict[2]['gt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{97: 93, 62: 56, 63: 61, 48: 32, 29: 28, 167: 160, 225: 223, 149: 148, 15: 13, 42: 31, 105: 102, 156: 144, 246: 239, 52: 50, 87: 81, 94: 89, 243: 221, 25: 17, 71: 69, 33: 30}\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# 创建一个空的图\n",
    "G = nx.Graph()\n",
    "\n",
    "# 添加轨迹中的节点\n",
    "G.add_nodes_from([i+1 for i in range(248)])  # 假设有四个物体\n",
    "\n",
    "# 添加可能的匹配关系\n",
    "G.add_edges_from([(13, 15), (13, 17), (15, 17), (17, 25), (25, 28), (25, 29), (28, 29), (30, 33),\n",
    "                  (31, 42), (32, 48), (50, 52), (56, 62), (59, 62), (61, 63), (69, 70), (69, 71),\n",
    "                  (70, 71), (81, 87), (87, 93), (89, 94), (93, 97), (97, 102), (102, 105), (140, 144),\n",
    "                  (144, 156), (148, 149), (160, 167), (220, 221), (221, 243), (223, 225), (239, 246)])\n",
    "\n",
    "matches = nx.max_weight_matching(G)\n",
    "\n",
    "matching = {match[0]: match[1] for match in matches}\n",
    "print(matching)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小开销的最大匹配： [[13, 15], [17, 25], [28, 29], [30, 33], [31, 42], [32, 48], [50, 52], [56, 62], [61, 63], [69, 70], [81, 87], [89, 94], [93, 97], [102, 105], [144, 156], [148, 149], [160, 167], [220, 221], [223, 225], [239, 246]]\n",
      "总开销： 0.8822851849597683\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "data = [\n",
    "    (13, 15, 0.055919863534040326),\n",
    "    (13, 17, 0.08391072678523503),\n",
    "    (15, 17, 0.04675545819863314),\n",
    "    (17, 25, 0.0952795234440611),\n",
    "    (25, 28, 0.026061762853108905),\n",
    "    (25, 29, 0.07769999145211681),\n",
    "    (28, 29, 0.06429536213721243),\n",
    "    (30, 33, 0.011018822541591144),\n",
    "    (31, 42, 0.0032972466303688996),\n",
    "    (32, 48, 0.0123805179843548),\n",
    "    (50, 52, 0.0701107722938773),\n",
    "    (56, 62, 0.0547255210469495),\n",
    "    (59, 62, 0.08732068893904366),\n",
    "    (61, 63, 0.025067058920953844),\n",
    "    (69, 70, 0.03126330983452186),\n",
    "    (69, 71, 0.08885931788413104),\n",
    "    (70, 71, 0.06542229866947713),\n",
    "    (81, 87, 0.08074798773585701),\n",
    "    (87, 93, 0.01306705159136512),\n",
    "    (89, 94, 0.05456472355144193),\n",
    "    (93, 97, 0.0063138966862459345),\n",
    "    (97, 102, 0.005156913682248465),\n",
    "    (102, 105, 0.010204292378161117),\n",
    "    (140, 144, 0.06941224334162688),\n",
    "    (144, 156, 0.0019342776181883181),\n",
    "    (148, 149, 0.039947646171244466),\n",
    "    (160, 167, 0.07879986959907326),\n",
    "    (220, 221, 0.08329987716767429),\n",
    "    (221, 243, 0.08558056966587291),\n",
    "    (223, 225, 0.031897507880611964),\n",
    "    (239, 246, 0.07121710780333879)\n",
    "]\n",
    "\n",
    "G = nx.Graph()\n",
    "for edge in data:\n",
    "    G.add_edge(edge[0], edge[1], weight=-edge[2])  # 负号转换为最小权重匹配\n",
    "\n",
    "# 使用最大权匹配算法寻找最小权重匹配\n",
    "matching = nx.max_weight_matching(G, maxcardinality=True)\n",
    "matching = sorted(matching, key=lambda x: x[0])\n",
    "sorted_matching = []\n",
    "for a,b in matching:\n",
    "    if a > b:\n",
    "        a, b = b, a\n",
    "    sorted_matching.append([a,b])\n",
    "# 计算总的最小权重\n",
    "total_cost = sum(-G[edge[0]][edge[1]]['weight'] for edge in matching)\n",
    "print(\"最小开销的最大匹配：\", sorted_matching)\n",
    "print(\"总开销：\", total_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp differences between c033 and c036:\n",
      "15.912500000000001\n",
      "Timestamp differences between c033 and c010:\n",
      "nan\n",
      "Timestamp differences between c033 and c014:\n",
      "nan\n",
      "Timestamp differences between c033 and c040:\n",
      "-8.4\n",
      "Timestamp differences between c036 and c010:\n",
      "nan\n",
      "Timestamp differences between c036 and c014:\n",
      "nan\n",
      "Timestamp differences between c036 and c040:\n",
      "5.88\n",
      "Timestamp differences between c010 and c014:\n",
      "4.383333333333334\n",
      "Timestamp differences between c010 and c040:\n",
      "nan\n",
      "Timestamp differences between c014 and c040:\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/xiayuyang/anaconda3/envs/carla/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/data1/xiayuyang/anaconda3/envs/carla/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# time diff = in time - out time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "# 统计每个gt文件中的轨迹id及出现的时间\n",
    "\n",
    "vdo_rate = 10\n",
    "cams_path = 'datasets/AIC22_Track1_MTMC_Tracking/train/S03'\n",
    "timestamp_file = 'datasets/AIC22_Track1_MTMC_Tracking/cam_timestamp/S03.txt'\n",
    "\n",
    "cam_names = os.listdir(cams_path)\n",
    "timestamp_dict = {}\n",
    "with open(timestamp_file, 'r') as time_file:\n",
    "    for line in time_file:\n",
    "        cam_name, stamp = line.strip().split(' ')\n",
    "        timestamp_dict[cam_name] = int(float(stamp) * vdo_rate)\n",
    "data = {}\n",
    "for cam in cam_names:\n",
    "    gt_file = f'{cams_path}/{cam}/gt/gt.txt'\n",
    "    with open(gt_file, 'r') as file:\n",
    "        for line in file:\n",
    "            # 以检测到的最后一帧为时间起点\n",
    "            last_frame, tid = list(line[:-12].strip().split(','))[:2]\n",
    "            if (cam not in data.keys()):\n",
    "                data[cam] = {}\n",
    "            if tid not in data[cam]:\n",
    "                # 记录in_time\n",
    "                data[cam][tid] = {}\n",
    "                data[cam][tid][0] = int(last_frame) - timestamp_dict[cam]\n",
    "            # 记录out_time\n",
    "            data[cam][tid][1] = int(last_frame) - timestamp_dict[cam]\n",
    "\n",
    "timestamp_differences_dict = {}\n",
    "\n",
    "# 遍历所有摄像头组合\n",
    "for (camera1, trajectories1), (camera2, trajectories2) in itertools.combinations(data.items(), 2):\n",
    "    differences = []\n",
    "\n",
    "    # 遍历第一个摄像头的轨迹\n",
    "    for tid, time1 in trajectories1.items():\n",
    "        # 如果轨迹在第二个摄像头也存在，则计算timestamp差值\n",
    "        if tid in trajectories2:\n",
    "            time2 = trajectories2[tid]\n",
    "            if time1[0] > time2[0]:\n",
    "                difference = time1[0] - time2[1]\n",
    "            else:\n",
    "                difference = time2[0] - time1[1]\n",
    "            differences.append(difference / vdo_rate)\n",
    "\n",
    "    key = (camera1, camera2)\n",
    "    timestamp_differences_dict[key] = differences\n",
    "\n",
    "for cameras, differences in timestamp_differences_dict.items():\n",
    "    print(f\"Timestamp differences between {cameras[0]} and {cameras[1]}:\")\n",
    "    print(np.mean(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import motmetrics as mm\n",
    "\n",
    "acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "# data[frame_id]['gt'][2d-list]\n",
    "# key是帧号\n",
    "\n",
    "def read_data_from_txt(file_path):\n",
    "    data_dict = {}  # 最外层字典，key为tid\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # 从每一行提取tid、fid和bbox\n",
    "            fid, tid, x1,y1,w,h,a,b,c,d = map(int, line.strip().split(','))\n",
    "            bbox = [x1, y1, w, h]\n",
    "\n",
    "            # 将数据存储到字典中\n",
    "            if tid not in data_dict:\n",
    "                data_dict[tid] = {}  # 内层字典，key为fid\n",
    "            data_dict[tid][fid] = bbox\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "gt_dict = read_data_from_txt('datasets/AIC22_Track1_MTMC_Tracking/train/S12/c004/gt/gt.txt')\n",
    "dt_dict = read_data_from_txt('record/S12_record/my_mot_metrics/c004_gt_test.txt')\n",
    "\n",
    "data = {}\n",
    "\n",
    "for tid, v in dt_dict.items():\n",
    "    for fid, bbox in v.items():\n",
    "        if fid not in data:\n",
    "            data[fid] = {'gt':[]}\n",
    "        data[fid]['gt'].append([tid,bbox[0],bbox[1],bbox[2],bbox[3]])\n",
    "\n",
    "for tid, v in gt_dict.items():\n",
    "    for fid, bbox in v.items():\n",
    "        if fid not in data:\n",
    "            data[fid] = {}\n",
    "            data[fid]['gt'] = []\n",
    "            data[fid]['detections'] = []\n",
    "        if 'detections' not in data[fid]:\n",
    "            data[fid]['detections'] = []\n",
    "        data[fid]['detections'].append([tid,bbox[0],bbox[1],bbox[2],bbox[3]])\n",
    "\n",
    "for frame, frame_data in data.items():\n",
    "    gt = frame_data['gt']\n",
    "    detections = frame_data['detections']\n",
    "    # 提取gt轨迹id和bbox框\n",
    "    gt_ids = [item[0] for item in gt]\n",
    "    gt_bboxes = [item[1:] for item in gt]\n",
    "    # 提取检测结果id和bbox框\n",
    "    detection_ids = [item[0] for item in detections]\n",
    "    detection_bboxes = [item[1:] for item in detections]\n",
    "\n",
    "    dists = mm.distances.iou_matrix(gt_bboxes, detection_bboxes, max_iou=0.5)\n",
    "\n",
    "    acc.update(gt_ids, detection_ids, dists)\n",
    "\n",
    "mh = mm.metrics.create()\n",
    "summary = mh.compute(acc, metrics=['num_frames', 'idf1', 'idp', 'idr', \\\n",
    "                                     'recall', 'precision', 'num_objects', \\\n",
    "                                     'mostly_tracked', 'partially_tracked', \\\n",
    "                                     'mostly_lost', 'num_false_positives', \\\n",
    "                                     'num_misses', 'num_switches', \\\n",
    "                                     'num_fragmentations', 'mota', 'motp' \\\n",
    "                                    ], \\\n",
    "                      name='acc')\n",
    "strsummary = mm.io.render_summary(\n",
    "      summary,\n",
    "      #formatters={'mota' : '{:.2%}'.format},\n",
    "      namemap={'idf1': 'IDF1', 'idp': 'IDP', 'idr': 'IDR', 'recall': 'Rcll', \\\n",
    "               'precision': 'Prcn', 'num_objects': 'GT', \\\n",
    "               'mostly_tracked' : 'MT', 'partially_tracked': 'PT', \\\n",
    "               'mostly_lost' : 'ML', 'num_false_positives': 'FP', \\\n",
    "               'num_misses': 'FN', 'num_switches' : 'IDsw', \\\n",
    "               'num_fragmentations' : 'FM', 'mota': 'MOTA', 'motp' : 'MOTP',  \\\n",
    "              }\n",
    "  )\n",
    "print(strsummary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 100 saved as my_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def save_frame(video_path, frame_number, save_path):\n",
    "    # 打开视频文件\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # 检查视频是否成功打开\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Failed to open video file.\")\n",
    "        return\n",
    "\n",
    "    # 获取视频的帧率和总帧数\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # 检查所需帧是否在视频范围内\n",
    "    if frame_number < 0 or frame_number >= total_frames:\n",
    "        print(\"Error: Invalid frame number.\")\n",
    "        return\n",
    "\n",
    "    # 设置视频的位置到所需帧\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "    # 读取所需帧\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # 检查帧是否成功读取\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to read frame.\")\n",
    "        return\n",
    "\n",
    "    # 保存帧为图像文件\n",
    "    cv2.imwrite(save_path, frame)\n",
    "    print(f\"Frame {frame_number} saved as {save_path}\")\n",
    "\n",
    "    # 关闭视频文件\n",
    "    cap.release()\n",
    "\n",
    "# 调用函数，传入视频路径、帧数和保存路径\n",
    "video_path = \"datasets/AIC22_Track1_MTMC_Tracking/train/S13/c001/vdo.mp4\"  # 替换为你的视频路径\n",
    "frame_number = 100  # 替换为你想要获取的帧数\n",
    "save_path = \"my_image.jpg\"  # 替换为你想要保存的图像路径\n",
    "save_frame(video_path, frame_number, save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
